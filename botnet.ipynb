{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/goncaOzmen/Transfer-Learning-Based-Intrusion-Detection-in-5G-and-IoT-Networks/blob/main/botnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7_sjpUW1BZcl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from shutil import copyfile\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras import layers, losses, Sequential\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wm7gb_UNv48H",
        "outputId": "06b0d83e-3e84-4af7-a406-c2ef9699368f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Colab Notebooks\n",
            " 01_preprocessing.ipynb\n",
            "'05_1_machine_learning_implementation_for_attack_files .ipynb'\n",
            "'botnet.ipynb adlı not defterinin kopyası'\n",
            "'Copy of CyberAttackType'\n",
            "'Copy of IOT data for Intrusion detection using ML and DL'\n",
            "'Copy of IOT data for Intrusion detection using ML and DL (1)'\n",
            "'DCGAN_ile_Keras_Kullanarak_digit_Sentetik_Goruntu_ Olusturulmasi.ipynb'\n",
            " elYazi.ipynb\n",
            " guvenlikKapiUyg.ipynb\n",
            " hw6_skeleton2.ipynb\n",
            " hw6_skeleton.ipynb\n",
            " modeling.py\n",
            " np_2.ipynb\n",
            " ornek_tesseract.ipynb\n",
            " pre_processing.py\n",
            " run_classifier.py\n",
            "'run_classifier.py adlı not defterinin kopyası'\n",
            " temel_odevler.ipynb\n",
            "'Transfer Learning.ipynb'\n",
            " Untitled0.ipynb\n",
            " Untitled1.ipynb\n",
            " Untitled2.ipynb\n",
            " Untitled3.ipynb\n",
            " Untitled4.ipynb\n",
            " Untitled5.ipynb\n",
            " Untitled6.ipynb\n",
            " Untitled7.ipynb\n",
            " Untitled8.ipynb\n",
            "'Untitled8.ipynb adlı not defterinin kopyası'\n",
            " \u001b[0m\u001b[01;34muygIDS\u001b[0m/\n",
            " veri_3.ipynb\n"
          ]
        }
      ],
      "source": [
        "# Google Drive Mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/Colab Notebooks/\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uqUK37tov4zr",
        "outputId": "666b67b3-5b63-4720-fd4b-9899c20e9f55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '1.benign.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-3f56b44fd47a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbenign\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1.benign.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmirai_ack\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1.mirai.ack.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmirai_scan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1.mirai.scan.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmirai_syn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1.mirai.syn.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmirai_udp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1.mirai.udp.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1.benign.csv'"
          ]
        }
      ],
      "source": [
        "benign =pd.read_csv('1.benign.csv')\n",
        "mirai_ack =pd.read_csv('1.mirai.ack.csv')\n",
        "mirai_scan = pd.read_csv('1.mirai.scan.csv')\n",
        "mirai_syn = pd.read_csv('1.mirai.syn.csv')\n",
        "mirai_udp = pd.read_csv('1.mirai.udp.csv')\n",
        "mirai_udp_plain = pd.read_csv('1.mirai.udpplain.csv')\n",
        "gafgyt_combo = pd.read_csv('1.gafgyt.combo.csv')\n",
        "gafgyt_junk = pd.read_csv('1.gafgyt.junk.csv')\n",
        "gafgyt_scan = pd.read_csv('1.gafgyt.scan.csv')\n",
        "gafgyt_tcp = pd.read_csv('1.gafgyt.tcp.csv')\n",
        "gafgyt_udp = pd.read_csv('1.gafgyt.udp.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeSflskvzGqw"
      },
      "outputs": [],
      "source": [
        "benign = benign.sample(frac=0.50, replace=False)\n",
        "mirai_ack = mirai_ack.sample(frac=0.24, replace=False)\n",
        "mirai_scan = mirai_scan.sample(frac=0.22, replace=False)\n",
        "mirai_syn = mirai_syn.sample(frac=0.2, replace=False)\n",
        "mirai_udp = mirai_udp.sample(frac=0.1, replace=False)\n",
        "mirai_udp_plain = mirai_udp_plain.sample(frac=0.3, replace=False)\n",
        "\n",
        "gafgyt_combo = gafgyt_combo.sample(frac=0.4, replace=False)\n",
        "gafgyt_junk = gafgyt_junk.sample(frac=0.8, replace=False)\n",
        "gafgyt_scan = gafgyt_scan.sample(frac=0.8, replace=False)\n",
        "gafgyt_tcp = gafgyt_tcp.sample(frac=0.25, replace=False)\n",
        "gafgyt_udp = gafgyt_udp.sample(frac=0.23, replace=False)\n",
        "\n",
        "benign['type']='benign'\n",
        "mirai_ack['type']='mirai_ack'\n",
        "mirai_scan['type']='mirai_scan'\n",
        "mirai_syn['type'] = 'mirai_syn'\n",
        "mirai_udp['type'] = 'mirai_udp'\n",
        "mirai_udp_plain['type'] = 'mirai_udp_plain'\n",
        "\n",
        "gafgyt_combo['type'] = 'gafgyt_combo'\n",
        "gafgyt_junk['type'] = 'gafgyt_junk'\n",
        "gafgyt_scan['type'] = 'gafgyt_scan'\n",
        "gafgyt_tcp['type'] = 'gafgyt_tcp'\n",
        "gafgyt_udp['type'] = 'gafgyt_udp'\n",
        "\n",
        "data = pd.concat([benign,\n",
        "                  mirai_ack, mirai_scan, mirai_syn, mirai_udp, mirai_udp_plain,\n",
        "                 gafgyt_combo, gafgyt_junk, gafgyt_scan, gafgyt_tcp, gafgyt_udp],\n",
        "                 axis=0, sort=False, ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfRxI5CwkUs6"
      },
      "outputs": [],
      "source": [
        "data.groupby('type')['type'].count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDda29NaCpjT"
      },
      "outputs": [],
      "source": [
        "benign.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8kkX7FElI2l"
      },
      "outputs": [],
      "source": [
        "#Shuffling rows of the dataframe\n",
        "sampler = np.random.permutation(len(data))\n",
        "data = data.take(sampler)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1idIMZC1lb_V"
      },
      "outputs": [],
      "source": [
        "features = data.drop(['type'], axis=1)\n",
        "target = data.filter(['type'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsaGAWahlmuc"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "data_st = scaler.fit_transform(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Knd0EBjXluc2"
      },
      "outputs": [],
      "source": [
        "# Encode target column data\n",
        "target.type = target.type.replace('benign', 0).replace('mirai_ack', 1).replace('mirai_scan', 2).replace('mirai_syn', 3).replace('mirai_udp', 4).replace('mirai_udp_plain', 5).replace('gafgyt_combo', 6).replace('gafgyt_junk', 7).replace('gafgyt_scan', 8).replace('gafgyt_tcp', 9).replace('gafgyt_udp', 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJRF5A2Gl7DC"
      },
      "outputs": [],
      "source": [
        "# Create dataset\n",
        "data_v2 = {'data': data_st, 'target': np.array(target['type'].values)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4O6UWzNfllv"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Split data into Train/test 25% datasets\n",
        "(iot_train, iot_test,\n",
        " iot_train_tgt, iot_test_tgt) = train_test_split(data_v2['data'],\n",
        "                                                 data_v2['target'],\n",
        "                                                 test_size=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvMg93zsclIV"
      },
      "outputs": [],
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn import discriminant_analysis\n",
        "from sklearn import naive_bayes\n",
        "from sklearn import svm\n",
        "from sklearn import tree\n",
        "from sklearn import neighbors\n",
        "import sklearn.metrics as metrics\n",
        "import sklearn.model_selection as skms\n",
        "import sklearn.preprocessing as skpre\n",
        "import sklearn.multiclass as skmulti"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier #\n",
        "from sklearn.ensemble import AdaBoostClassifier #\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.svm import SVC #\n",
        "from sklearn.neighbors import KNeighborsClassifier #\n",
        "from sklearn.tree import DecisionTreeClassifier #\n",
        "\n",
        "from xgboost import XGBClassifier #"
      ],
      "metadata": {
        "id": "fJuG9NdhiNBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3GUEdlVmETx"
      },
      "outputs": [],
      "source": [
        "classifiers = {'XGB': XGBClassifier(random_state=3, learning_rate=0.05, max_depth=10, n_estimators=100),\n",
        "         'AdaBoost Classifier': AdaBoostClassifier(n_estimators=20),\n",
        "         'Random Forest':  RandomForestClassifier(),\n",
        "         'QDA': discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
        "         'LDA': discriminant_analysis.LinearDiscriminantAnalysis(),\n",
        "         'GNB': naive_bayes.GaussianNB(),\n",
        "\n",
        "         'SVC(1)': svm.SVC(kernel=\"linear\"),\n",
        "         'SVC(2)': svm.LinearSVC(),\n",
        "\n",
        "         'DTC': tree.DecisionTreeClassifier(),\n",
        "         '5NN-C': neighbors.KNeighborsClassifier(),\n",
        "         '10NN-C': neighbors.KNeighborsClassifier(n_neighbors=10)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xu37qki3myp-"
      },
      "outputs": [],
      "source": [
        "pr_test=[]\n",
        "for name, model in classifiers.items():\n",
        "    model.fit(iot_train, iot_train_tgt)\n",
        "    preds = model.predict(iot_test)\n",
        "    pr_test.append(preds)\n",
        "\n",
        "#knn_score =metrics.accuracy_score(iot_test_tgt, preds)\n",
        "#print(\"{:>4s}: {:5.2f}\".format(name, knn_score))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_score\n",
        "Name= 'rawDataRes'\n",
        "res=[]\n",
        "output=[]\n",
        "output2=[]\n",
        "for (i, v),Xpred in zip(classifiers.items(),pr_test):\n",
        "    row= {}\n",
        "    #Xpred =  v.predict(iot_test)\n",
        "    #scores = cross_val_score(v, iot_train, iot_train_tgt, cv=5)\n",
        "    accuracy = metrics.accuracy_score(iot_test_tgt, Xpred)\n",
        "    confusion_matrix = metrics.confusion_matrix(iot_test_tgt, Xpred)\n",
        "    classification = metrics.classification_report(iot_test_tgt, Xpred)\n",
        "\n",
        "    lines = classification.split('\\n')\n",
        "    line = lines[7:-1][0]\n",
        "    row_data = line.split('      ')\n",
        "    row ['Tst Accuracy'] = accuracy\n",
        "    row ['Tst CV mean'] = scores.mean()\n",
        "    row ['Tst Precision'] = float(row_data[1])\n",
        "    row ['Tst Recall'] = float(row_data[2])\n",
        "    row ['Tst F1-Score'] = float(row_data[3])\n",
        "    row ['Tst TN'] = confusion_matrix[0][0]\n",
        "    row ['Tst FP'] = confusion_matrix[0][1]\n",
        "    row ['Tst FN'] = confusion_matrix[1][0]\n",
        "    row ['Tst TP'] = confusion_matrix[1][1]\n",
        "    output2.append('.......................{} test Model Evaluation =============================='.format(i))\n",
        "    output2.append(\"Cross Validation Mean Score: \")\n",
        "    output2.append(scores.mean())\n",
        "    output2.append(\"Model Accuracy: \")\n",
        "    output2.append(accuracy)\n",
        "    output2.append(\"Confusion matrix:\")\n",
        "    output2.append(confusion_matrix)\n",
        "    output2.append(\"Classification report:\")\n",
        "    output2.append(classification)\n",
        "    res.append(row)\n",
        "pd.DataFrame.from_dict(res).to_csv('TestResult.csv',index=False)"
      ],
      "metadata": {
        "id": "ZTXPPoD_j-ns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame.from_dict(res).to_csv('TestResult2.csv',index=False)"
      ],
      "metadata": {
        "id": "cxF6Puzct5j6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output2"
      ],
      "metadata": {
        "id": "uiYTv8RKvvWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(res)"
      ],
      "metadata": {
        "id": "-sqHz2Cnt6ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame.from_dict(pr_test).to_csv('TestPrediction.csv',index=False)"
      ],
      "metadata": {
        "id": "f9ha8uRflHgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbZeW4M_m9Ew"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2,4, figsize=(30, 15),\n",
        "                        sharex=True, sharey=True)\n",
        "\n",
        "for ax, (name, model) in zip(axes.flat, classifiers.items()):\n",
        "    preds = (model.fit(iot_train, iot_train_tgt)\n",
        "            .predict(iot_test))\n",
        "    cm = metrics.confusion_matrix(iot_test_tgt, preds)\n",
        "    sns.heatmap(cm, annot=True, cbar=False, ax=ax)\n",
        "    ax.set_title(name)\n",
        "\n",
        "axes[0,0].set_ylabel('Actual')\n",
        "axes[1,0].set_xlabel('Predicted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39IAZmpanobr"
      },
      "outputs": [],
      "source": [
        "def compute_readability(text):Text(0.5, 114.00000000000011, 'Predicted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BC6rPQqTnwWX"
      },
      "outputs": [],
      "source": [
        "## Atempted to display on single graph using multiclass. Didn't work out. Switched to one vs rest below\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(20,10))\n",
        "cv_prob_true = {}\n",
        "for name, model in classifiers.items():\n",
        "    cv_probs = skms.cross_val_predict(model, iot_train, iot_train_tgt,\n",
        "                                     cv=10, method='predict_proba')\n",
        "    cv_prob_true[name] = cv_probs[:,1]\n",
        "    fpr, tpr, thresh = metrics.roc_curve(iot_train_tgt,\n",
        "                                         cv_prob_true[name])\n",
        "    auc = metrics.auc(fpr, tpr)\n",
        "    ax.plot(fpr, tpr, 'o--', label=\"{}:{}\".format(name, auc))\n",
        "    ax.set_title('ROC Curves')\n",
        "    ax.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNVUvGvjn4ab"
      },
      "outputs": [],
      "source": [
        "#Lift one vs rest. There's also a lift one vs rest with all curves in one graph below\n",
        "\n",
        "iot_multi_tgt = skpre.label_binarize(data_v2['target'],classes=[0,1,2,3,4,5,6,7,8,9, 10])\n",
        "\n",
        "\n",
        "(iotmulti_train_ftrs, iotmulti_test_ftrs,\n",
        "iotmulti_train_tgt, iotmulti_test_tgt) = skms.train_test_split(data_v2['data'], iot_multi_tgt, test_size=.33)\n",
        "\n",
        "is_first = data_v2['target'] == 1\n",
        "tts_1c = skms.train_test_split(data_v2['data'], is_first, test_size=.33)\n",
        "\n",
        "(iot_1c_train_ftrs, iot_1c_test_ftrs,\n",
        "iot_1c_train_tgt, iot_1c_test_tgt) = tts_1c\n",
        "\n",
        "for name, model in classifiers.items():\n",
        "    prob_true = (model.fit(iot_1c_train_ftrs, iot_1c_train_tgt).predict_proba(iot_1c_test_ftrs)[:,1])\n",
        "\n",
        "    #negate because we want big values first\n",
        "    myorder = np.argsort(-prob_true)\n",
        "\n",
        "    #cumulative sum then to percent (last value is total)\n",
        "    realpct_myorder = iot_1c_test_tgt[myorder].cumsum()\n",
        "    realpct_myorder = realpct_myorder / realpct_myorder[-1]\n",
        "\n",
        "    # convert counts of data into percents\n",
        "    N = iot_1c_test_tgt.size\n",
        "    xs = np.linspace(1/N, 1, N)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8,4))\n",
        "    fig.tight_layout()\n",
        "\n",
        "    ax.plot(xs, realpct_myorder / np.where(xs > 0, xs, 1))\n",
        "    ax.set_title(\"Lift \" + name)\n",
        "    ax.set_ylabel(\"X-Fold Improvement\")\n",
        "    ax.set_xlabel(\"Percent of Population\\n\" + \"Starting with Highest Predicted Hits\")\n",
        "    ax.yaxis.tick_right()\n",
        "    ax.yaxis.set_label_position('right')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HbBrPphooiW"
      },
      "outputs": [],
      "source": [
        "#Lift one vs rest\n",
        "\n",
        "iot_multi_tgt = skpre.label_binarize(data_v2['target'], classes=[0,1,2,3,4,5,6,7,8,9, 10])\n",
        "\n",
        "\n",
        "(iotmulti_train_ftrs, iotmulti_test_ftrs,\n",
        "iotmulti_train_tgt, iotmulti_test_tgt) = skms.train_test_split(data_v2['data'], iot_multi_tgt, test_size=.33)\n",
        "\n",
        "is_first = data_v2['target'] == 1\n",
        "tts_1c = skms.train_test_split(data_v2['data'], is_first, test_size=.33)\n",
        "\n",
        "(iot_1c_train_ftrs, iot_1c_test_ftrs,\n",
        "iot_1c_train_tgt, iot_1c_test_tgt) = tts_1c\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8,4))\n",
        "fig.tight_layout()\n",
        "for name, model in classifiers.items():\n",
        "        prob_true = (model.fit(iot_1c_train_ftrs, iot_1c_train_tgt)\n",
        "                     .predict(iot_1c_test_ftrs)[:,1])\n",
        "\n",
        "        #negate because we want big values first\n",
        "        myorder = np.argsort(-prob_true)\n",
        "        #cumulative sum then to percent (last value is total)\n",
        "        realpct_myorder = iot_1c_test_tgt[myorder].cumsum()\n",
        "        realpct_myorder = realpct_myorder / realpct_myorder[-1]\n",
        "\n",
        "        # convert counts of data into percents\n",
        "        N = iot_1c_test_tgt.size\n",
        "        xs = np.linspace(1/N, 1, N)\n",
        "\n",
        "        ax.plot(xs, realpct_myorder / np.where(xs > 0, xs, 1), label=\"{}\".format(name))\n",
        "\n",
        "        ax.set_title(\"Lift \" + name)\n",
        "        ax.set_ylabel(\"X-Fold Improvement\")\n",
        "        ax.set_xlabel(\"Percent of Population\\n\" + \"Starting with Highest Predicted Hits\")\n",
        "        ax.yaxis.tick_right()\n",
        "        ax.yaxis.set_label_position('right')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oqy8y2-bpASk"
      },
      "outputs": [],
      "source": [
        "iot_multi_tgt = skpre.label_binarize(data_v2['target'], classes=[0,1,2,3,4,5,6,7,8,9,10])\n",
        "\n",
        "(im_train_ftrs, im_test_ftrs,\n",
        "im_train_tgt, im_test_tgt) = skms.train_test_split(data_v2['data'], iot_multi_tgt, test_size=.33)\n",
        "\n",
        "for name, model in classifiers.items():\n",
        "    ovr_model = skmulti.OneVsRestClassifier(model)\n",
        "    pred_probs = ovr_model.fit(im_train_ftrs, im_train_tgt).predict_proba(im_test_ftrs)\n",
        "\n",
        "    lbl_fmt = \"Class {} vs Rest (AUC = {:.2f}) / {}\"\n",
        "    fig, ax = plt.subplots(figsize=(8,4))\n",
        "    for cls in [0,1,2,3,4,5,6,7,8,9,10]:\n",
        "        fpr, tpr, _ = metrics.roc_curve(im_test_tgt[:,cls],\n",
        "                                       pred_probs[:,cls])\n",
        "        label = lbl_fmt.format(cls, metrics.auc(fpr, tpr), name)\n",
        "        ax.plot(fpr, tpr, 'o--', label=label)\n",
        "\n",
        "    ax.legend()\n",
        "    ax.set_xlabel(\"FPR\")\n",
        "    ax.set_ylabel(\"TPR\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "965hs-UHp05t"
      },
      "outputs": [],
      "source": [
        "#Precision\n",
        "\n",
        "iot_multi_tgt = skpre.label_binarize(data_v2['target'], classes=[0,1,2,3,4,5,6,7,8,9,10])\n",
        "\n",
        "(im_train_ftrs, im_test_ftrs,\n",
        " im_train_tgt, im_test_tgt) = skms.train_test_split(data_v2['data'],\n",
        "                                                   iot_multi_tgt,\n",
        "                                                   test_size=.33)\n",
        "\n",
        "for name, model in classifiers.items():\n",
        "    ovr_model = skmulti.OneVsRestClassifier(model)\n",
        "    pred_probs = ovr_model.fit(im_train_ftrs, im_train_tgt).predict_proba(im_test_ftrs)\n",
        "\n",
        "\n",
        "    lbl_format = \"Class {} vs Rest (AUC = {:.2f}) / {}\"\n",
        "    fig, ax = plt.subplots(figsize=(8,4))\n",
        "    for cls in [0,1,2,3,4,5,6,7,8,9,10]:\n",
        "        prc = metrics.precision_recall_curve\n",
        "        precision, recall, _ =prc(im_test_tgt[:,cls],\n",
        "                                 pred_probs[:,cls])\n",
        "        prc_auc = metrics.auc(recall, precision)\n",
        "        label = lbl_format.format(cls, prc_auc, name)\n",
        "        ax.plot(recall, precision, 'o--', label=label)\n",
        "\n",
        "    ax.legend()\n",
        "    ax.set_xlabel(\"Recall\")\n",
        "    ax.set_ylabel(\"Precision\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCSpZK8pqSsK"
      },
      "outputs": [],
      "source": [
        "fig, (ax2) = plt.subplots(1, 1, figsize=(20, 10))\n",
        "N = len(iot_train_tgt)\n",
        "xs = np.linspace(1/N, 1, N)\n",
        "for name, model in classifiers.items():\n",
        "    # Negate so big values come first\n",
        "    myorder = np.argsort(-cv_prob_true[name])\n",
        "    realpct_myorder = iot_train_tgt[myorder].cumsum()\n",
        "    realpct_myorder = realpct_myorder /realpct_myorder[-1]\n",
        "    ax2.plot(xs, realpct_myorder / np.where(xs > 0, xs, 1), label=name)\n",
        "ax2.legend()\n",
        "ax2.set_title(\"Lift versus Random\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ue-WJslvqjLQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "macro_precision = metrics.make_scorer(metrics.precision_score, average='macro')\n",
        "macro_recall = metrics.make_scorer(metrics.recall_score, average='macro')\n",
        "\n",
        "msrs = ['accuracy', macro_precision, macro_recall]\n",
        "\n",
        "fig, axes = plt.subplots(len(msrs), 1, figsize)=(10, 2*len(msrs))\n",
        "fig.tight_layout()\n",
        "\n",
        "for name, model in classifiers.items():\n",
        "    cvs = skms.cross_val_score\n",
        "    cvs_results = {msr:cvs(model, iot_train, iot_train_tgt,\n",
        "                          scoring=msr, cv=10) for msr in msrs}\n",
        "\n",
        "    for ax, msr in zip(axes, msrs):\n",
        "        msr_results = cv_results[msr]\n",
        "        my_lbl = \"{:12s} {:.3f} {:.2f}\".format(name, msr_results.mean(), msr_results.std())\n",
        "        ax.plot(msr_results, 'o--', label=my_lbl)\n",
        "        ax.set_title(msr)\n",
        "        ax.legend(loc='lower left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXvoi2ATrYIH"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(6,4))\n",
        "\n",
        "for name, model in classifiers.items():\n",
        "    cv_scores = skms.cross_val_score(model, data_v2['data'], data_v2['target'], cv=10,\n",
        "                                    scoring='accuracy', n_jobs=-1)\n",
        "    my_lbl= \"{} {:4.3f}\".format(name, cv_scores.mean())\n",
        "    ax.plot(cv_scores, '-o', label=my_lbl)\n",
        "\n",
        "ax.set_ylim(0.0, 1.1)\n",
        "ax.set_xlabel('Fold')\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.legend(ncol=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuvEJagPrqgf"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "model = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
        "scores = skms.cross_val_score(model, data_v2['data'], data_v2['target'],\n",
        "                             cv=5, scoring='neg_mean_squared_error')\n",
        "scores = pd.Series(np.sqrt(-scores))\n",
        "\n",
        "df = pd.DataFrame({'RMSE':scores})\n",
        "df.index.name = 'Repeat'\n",
        "display(df.describe().T)\n",
        "ax = sns.swarmplot(y='RMSE', data=df)\n",
        "ax.set_xlabel('Over Repeated\\nTrain-Test Splits')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}